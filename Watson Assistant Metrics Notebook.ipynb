{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Watson Assistant Performance Metrics [Client Name]\n\nThis notebook performs analytics on the user log records of Watson Assistant (including Voice Interaction). A variety of key business metrics (listed below in Table of Contents) are calculated and displayed in the notebook. The data and metrics are also saved to CSV and can be used for building visualizations in a Cognos Dashboard in Watson Studio. \n\nLogs can also be exported to spreadsheet in Section 3.0 to perform blind testing in order to improve the performance of your virtual agent.\n\n### Table of Contents\n* [1.0 Configuration and Log Collection](#config)\n* [2.0 Key Performance Metrics](#performance-metrics)\n    * [2.1 Core Metrics](#core-metrics)\n        * [2.1.1 Abandonment at Greeting](#abandonment)\n        * [2.1.2 Coverage Metric](#coverage-metric)\n        * [2.1.3 Escalation Metric](#escalation-metric)\n        * [2.1.4 Active Users](active-users)\n        * [2.1.5 Top Intents & Average Confidence Scores](#top-intents-scores)\n        * [2.1.6 Top Entities](#top-entities)\n        * [2.1.7 Optional: Bilingual Assistants](#bilingual-assistants)\n    * [2.2 Voice Interaction Metrics](#voice-metrics)\n        * [2.2.1 Containment Rate](#containment-rate)\n        * [2.2.2 Active Callers](#active-callers)\n        * [2.2.3 SMS Sent](#sms-sent)\n    * [2.3 Custom Metrics](#custom-metrics)\n        * [2.3.1 Context Variable Count](#context-variable-count)\n        * [2.3.2 Response Mentions](#response-mentions)\n    * [2.4 Export to CSV](#export-to-csv)\n* [3.0 Collecting data for blind testing or new ground truth](#blind-testing)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Housekeeping <a class=\"anchor\" id=\"housekeeping\"></a>\nThis section will import libraries and dependencies for this notebook. \n\n**Action Required:** \n- Update the `project_id` and `project_access_token` in order to access your data assets.\n- Upload `getAllLogs.py` and `extractConversations.py` into your project's assets. They can be found at https://github.com/cognitive-catalyst/WA-Testing-Tool/tree/master/log_analytics"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Import dependencies. Ensure these are loaded into your Studio assets.\nfobj = open(\"getAllLogs.py\", \"wb\")\nfobj.write(project.get_file(\"getAllLogs.py\").read()) \nfobj.close()\n\nfobj = open(\"extractConversations.py\", \"wb\")\nfobj.write(project.get_file(\"extractConversations.py\").read()) \nfobj.close()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n!pip install ibm-watson\n!pip install --user --upgrade \"plotly_express==0.4.0\";\n!pip install --user --upgrade \"matplotlib==3.2.1\";\n!pip install squarify\n\nimport json\nimport pandas as pd\nimport getAllLogs\nimport extractConversations\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport matplotlib.pyplot as plt "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Custom functions to re-use code throughout notebook\ndef turn_dict_to_df(df,col_names):\n    df = pd.DataFrame.from_dict(df)\n    df.reset_index(level=0, inplace=True)\n    df.columns = col_names\n    return df"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 1.0 Configuration and log collection <a class=\"anchor\" id=\"config\"></a>\nThe next few cells require some configuration.  Review the variables and update them for your specific assistant.  The comments in the cells guide you in the configuration."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Action Required: Define the customer name. This prefix will be used for saving CSV & JSON files.\ncustName = 'XXXXXXX'"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 1.1 Option One: Retrieve logs from the Watson Assistant instance\nThis option will allow you to retrieve the logs from the Assistant API.\n\n- **For Chat** solutions using an Assistant layer (e.g. web chat), set `workspace_id=None` and provide `assistant_id` filter\n- **For Voice Interaction** solutions, define `workspace_id` and leave `assistant_id` filter blank/commented out\n\nUpdate `log_filter` for any other filters, e.g. update `response_timestamp` if you wish to limit the amount of data retrieved."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Extract logs from your assistant. Comment entire cell out if you are using existing logs in next step.\n\n# API, URL,and workspace ID are extractable from \"View API Details page\"\niam_apikey='XXXXXXXXXXXXXX' # Update this\n\n#url pattern depends on region and when it was created (update one to match your instance)\nurl=\"https://api.us-south.assistant.watson.cloud.ibm.com\"\n#url=\"https://api.us-east.assistant.watson.cloud.ibm.com\"\n\nworkspace_id='XXXXXXXXXXXXXX' # Update or set to None without quotes\n\n# Filter API is described at: https://cloud.ibm.com/docs/assistant?topic=assistant-filter-reference#filter-reference\nlog_filter=\"language::en,response_timestamp>=2020-05-15\" \\\n# +\",request.context.system.assistant_id::<<assistant_id>>\" # If using this, uncomment and replace <<assistant_id>>\n\n#Change the number of logs retrieved, default settings will return 100,000 logs (200 pages of 500)\npage_size_limit=500\npage_num_limit=200\n\n#WA API version\nversion=\"2018-09-20\" \n\nrawLogsJson = getAllLogs.getLogs(iam_apikey, url, workspace_id, log_filter, page_size_limit, page_num_limit, version)\nrawLogsPath= custName + \"_logs.json\"\n\n# getAllLogs.writeLogs(rawLogsJson, rawLogsPath) # Saves the logs locally\nproject.save_data(file_name = rawLogsPath,data = json.dumps(rawLogsJson),overwrite=True); # Saves the logs in Studio/COS\nprint('\\nSaved log data to {}'.format(rawLogsPath))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 1.2 Option Two: Load logs from JSON file\nIf you have previously saved the JSON file, you can uncomment this section to load the logs. Otherwise, comment this section out and continue."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# #If you have previously stored your logs on the file system, you can reload them here by uncommenting these lines\n# rawLogsPath= custName+\"_logs.json\"\n# rawLogsJson = extractConversations.readLogs(rawLogsPath)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 1.3 Format logs\nUpdate these fields by following the instructions in the comments."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Define the conversation corrrelation field name for your Watson Assistant records.\n# Provide the field name as it appears in the log payload (default is 'response.context.conversation_id')\n# For a single-skill assistant use 'response.context.conversation_id'\n# For a Voice Gateway/Voice Agent assistant use 'request.context.vgwSessionID'\n# For a multi-skill assistant you will need to provide your own key\nprimaryLogKey = \"response.context.conversation_id\"\n\n# Name of the correlating key as it appears in the data frame columns (remove 'response.context.')\nconversationKey='conversation_id'\n\n# Optionally provide a comma-separated list of custom fields you want to extract, in addition to the default fields\n#customFieldNames = \"response.context.STT_CONFIDENCE,response.context.action,response.context.vgwBargeInOccurred\"\ncustomFieldNames = \"response.context.vgwSIPFromURI,response.context.vgwSessionID,request.context.vgwSMSFailureReason,\\\nrequest.context.vgwSMSUserPhoneNumber,response.context.user_record.calling_about_child,response.context.user_record.covidExposure,\\\nresponse.context.user_record.covidSymptoms,response.output.vgwAction.parameters.transferTarget,response.context.language,\\\nresponse.context.metadata.user_id\"\n\n\nallLogsDF = extractConversations.extractConversationData(rawLogsJson, primaryLogKey, customFieldNames)\nconversationsGroup = allLogsDF.groupby(conversationKey,as_index=False)\n\nprint(\"Total log events:\",len(allLogsDF))\nallLogsDF.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "allLogsDF.columns"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Splits the response_timestamp into month, day, and year fields that can be used for Cognos visualizations\nallLogsDF[\"full_date\"] = pd.to_datetime(allLogsDF[\"response_timestamp\"])\nallLogsDF['month'] = allLogsDF['full_date'].dt.month\nallLogsDF['year'] = allLogsDF['full_date'].dt.year\nallLogsDF['day'] = allLogsDF['full_date'].dt.day"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# 2.0 Key Performance Metrics <a class=\"anchor\" id=\"performance-metrics\"></a>\nThe notebook will calculate various performance metrics including `coverage` and `containment`. Basic volume metrics will also be provided.\n\n- **2.1 Core Metrics:** These are conversational metrics that apply to both chat and voice solutions.\n- **2.2 Voice Interaction Metrics:** Additional measurements for voice solutions including phone calls, call transfers, unique caller IDs, etc.\n- **2.3 Custom metrics:** Other ad-hoc analysis. Requires knowledge of Python.\n- **2.4 Export to CSV** Save total logs, key metrics, and uncovered messages to CSV"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2.1 Core Metrics <a class=\"anchor\" id=\"core-metrics\"></a>\nThese metrics apply to all Watson Assistant solutions. For voice solutions, additional metrics are in the next section."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Let's define a dict{} that we will send to CSV for use in Watson Studio Cognos Dashboard\nmetrics_dict = {}\n\n# These should match the count in the Watson Assistant Analytics tooling.\ntotalConvs = len(allLogsDF[conversationKey].unique())\nprint(\"Total messages:\", len(allLogsDF))\nprint(\"Total conversations:\", totalConvs)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.1.1 Abandonment at Greeting <a class=\"anchor\" id=\"abandonment\"></a>\n- Log events with a blank `input.text` are the greeting messages. This should equal total conversations.\n- Filtering out these messages will reveal how many conversations abandoned before the first user utterance."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Filter out blank inputs and vgwHangUp tags in log events\nfilteredLogsDF = allLogsDF[allLogsDF['input.text'] != \"\"]\nfilteredLogsDF = filteredLogsDF[filteredLogsDF['input.text'] != 'vgwHangUp'] \nfilteredLogsDF = filteredLogsDF[filteredLogsDF['input.text'] != 'vgwPostResponseTimeout'] \n\nfilteredMessages = len(filteredLogsDF)\nfilteredConvs = len(filteredLogsDF[conversationKey].unique())\nabandonedGreeting = (totalConvs - filteredConvs)\nmetrics_dict['abandonedGreeting'] = [abandonedGreeting] # Put into metrics dict\n\nprint(\"Total messages:\", filteredMessages)\nprint(\"Total conversations:\", filteredConvs)\nprint(\"Abandoned conversations:\", abandonedGreeting)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.1.2 Coverage Metric <a class=\"anchor\" id=\"coverage-metric\"></a>\nCoverage is the measurement of the portion of total user messages that your assistant is attempting to respond to. \n\n- **Action Required:** Define the node_ids in `anything_else_nodes` list that represent any responses for uncovered messages.\n- Coverage is then calculated by taking the number of visits to these nodes divided by total messages and subtracting one. \n- This metric filters out Voice Gateway actions such as `vgwHangUp`"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Define the node_id for anything_else and other uncovered nodes\nanything_else_nodes = ['XXXXXXXXXXXXXX'] \n\nfor row in filteredLogsDF.itertuples():\n    nodes = row.nodes_visited\n    for node in nodes:\n        if node in anything_else_nodes:\n            anything_else_nodes.append(row.Index)\n            \nuncoveredDF = filteredLogsDF[filteredLogsDF.index.isin(anything_else_nodes)]\n\nprint(\"Uncovered messages:\",len(uncoveredDF))\ncoverageMetric = 1-len(uncoveredDF)/filteredMessages\nmetrics_dict['coverage'] = [coverageMetric] # Put into metrics dict\nprint(\"Coverage metric is\",'{:.0%}'.format(coverageMetric))\n\nuncoveredDF = uncoveredDF[['input.text','output.text','intent','intent_confidence']]\n\nuncoveredDF.to_csv(custName + \"_uncovered_msgs.csv\",index=False, header=['Utterance','Response','Intent','Confidence'])\n\nuncoveredDF.head(10).sort_values('intent_confidence',ascending=False)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.1.3 Escalation Metric <a class=\"anchor\" id=\"escalation-metric\"></a>\nEscalation is defined as responding with a method to contact a live person (e.g. pointing to a 1-800 number). \n- **Action Required:** Define the node_id for where your assistant responds to an escalation request (e.g. `#General-Agent-Escalation`)\n- For Voice Interaction solutions, we calculate `call containment` in the next section by counting the number of call transfers in the logs. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Define the escalation node\nescalation_node = \"XXXXXXXXXXXXXX\" \nnode_visits_escalated = allLogsDF[[escalation_node in x for x in allLogsDF['nodes_visited']]]\n\nprint(\"Total visits to escalation node:\",len(node_visits_escalated))\n\nescalationMetric = len(node_visits_escalated)/filteredMessages\nmetrics_dict['escalation'] = [escalationMetric] # Put into metrics dict\nprint(\"\\nEscalation metric is\",'{:.0%}'.format(escalationMetric))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.1.4 Active Users <a class=\"anchor\" id=\"active-users\"></a>\nHow many unique users used the assistant?"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "uniqueUsers = allLogsDF[\"metadata.user_id\"].nunique()\nmetrics_dict['uniqueUsers'] = [uniqueUsers] # Put into metrics dict\nprint('Total unique users: {}'.format(uniqueUsers))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.1.5 Top Intents & Average Confidence Scores <a class=\"anchor\" id=\"top-intents-scores\"></a>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Using pandas aggregators to count how often each intent is selected and its average confidence\nintentsDF = filteredLogsDF.groupby('intent',as_index=False).agg({\n   'input.text': ['count'], \n   'intent_confidence': ['mean']\n})\n\nintentsDF.columns=[\"intent\",\"count\",\"confidence\"] #Flatten the column headers for ease of use\n\nintentsDF = intentsDF[intentsDF['intent'] !=''] # Remove blanks, usually VGW tags + greetings\nintentsDF = intentsDF.sort_values('count',ascending=False)\nintentsDF.head(5) # If you want specific number shown, edit inside head(). If you want to show all, remove head() "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ax = sns.barplot(x=\"count\", y=\"intent\", data=intentsDF.head(),orient='h',palette=\"Blues_d\").set_title('Top Intents')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.1.6 Top Entities (Skip for now) <a class=\"anchor\" id=\"top-entities\"></a>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "entityDF = allLogsDF[allLogsDF[\"entities\"] != \"\"]\n#intentsDF = intentsDF[intentsDF['intent'] !=''] # Remove blanks, usually VGW tags + greetings\nentityDF[\"entities\"].iloc[50]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# ax = sns.lineplot(x=\"week\", y=\"conversations\", data=trendDF,label='',sort=False).set_title('Weekly Conversations')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.1.7 Optional: Bilingual Assistants <a class=\"anchor\" id=\"bilingual-assistants\"></a>\nFor assistants that use a single skill for two different languages. The skill may set a context variable (e.g. `$language==\"english\"`) and then respond accordingly based on this variable. This cell will count the unique conversation_ids that have a given context variable.\n- **Action Required:** Define the `languageVar` that your skill uses to identify the language used to respond to the user."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "languageVar = 'language' # define the context variable that you retrieved above in customFields\n\nlanguageDF = allLogsDF.groupby([languageVar])[\"conversation_id\"].nunique()\nlanguageDF = turn_dict_to_df(languageDF, ['Context Var', 'Count'])\nlanguageDF = languageDF[languageDF['Context Var'] != '']\nlanguageDF"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2.2 Voice Interaction Metrics <a class=\"anchor\" id=\"voice-metrics\"></a>\nThese metrics are for Voice Agent solutions. We start with volume metrics."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "uniqueCallers = allLogsDF['vgwSIPFromURI'].unique()\nuniqueCalls = allLogsDF['vgwSessionID'].unique()\n\nprint(\"Total phone calls:\", len(uniqueCalls)) # It will print '1' if there are no calls found in the logs\nprint(\"Total unique callers:\", len(uniqueCallers))\nprint(\"Average messages per call:\", int(len(allLogsDF) / len(uniqueCalls)))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Filters out blank inputs and vgwHangUp tags in log events\nfilteredLogsDF = allLogsDF[allLogsDF['input.text'] != \"\"]\nfilteredLogsDF = filteredLogsDF[filteredLogsDF['input.text'] != 'vgwHangUp'] \nfilteredLogsDF = filteredLogsDF[filteredLogsDF['input.text'] != 'vgwPostResponseTimeout'] "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.2.1 Containment Rate <a class=\"anchor\" id=\"containment-rate\"></a>\nHow many call transfers did the voice solution perform?"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "transfersDF = allLogsDF.groupby([\"output.vgwAction.parameters.transferTarget\"])[\"vgwSessionID\"].count()\ntransfersDF = turn_dict_to_df(transfersDF, ['TransferTo', 'Count'])\ntransfersDF = transfersDF[transfersDF['TransferTo'] != '']\n\nprint('Call transfer count:', transfersDF['Count'].sum()) \ncontainmentRate = 1 - transfersDF['Count'].sum() / len(uniqueCalls)\nprint('Call containment rate:', '{:.0%}'.format(containmentRate))\nmetrics_dict['callTransfers'] = [transfersDF['Count'].sum()] # Put into metrics dict\nmetrics_dict['containment'] = [containmentRate] # Put into metrics dict\ntransfersDF.sort_values('Count',ascending=False)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.2.2 Active Callers <a class=\"anchor\" id=\"active-callers\"></a>\nHow many unique caller IDs dialed into the voice solution?"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "callsDF = allLogsDF.groupby(['vgwSIPFromURI'])['vgwSessionID'].nunique()\ncallsDF = pd.DataFrame.from_dict(callsDF)\ncallsDF.reset_index(level=0, inplace=True)\ncallsDF.columns = ['Caller ID', 'Call Count']\nprint('Total unique caller IDs:', len(callsDF))\ncallsDF.head().sort_values('Call Count',ascending=False)\nmetrics_dict['callerIDs'] = [len(callsDF)] # Put into metrics dict"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.2.3 SMS Sent <a class=\"anchor\" id=\"sms-sent\"></a>\nA text message can be sent to the caller and can be initiated from within the Watson Assistant JSON editor. This will count the number of SMS sent."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "smsDF = allLogsDF[allLogsDF['vgwSMSUserPhoneNumber'] != '']\nmetrics_dict['sms'] = [len(smsDF)] # Put into metrics dict\nprint('Total SMS sent to callers: {}'.format(len(smsDF)))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2.3 Custom Metrics <a class=\"anchor\" id=\"custom-metrics\"></a>\nThis section is optional and can be used to create custom metrics. It will require the basic knowledge of Python and Pandas. Two examples of custom metrics included below can be modified, or additional metrics can be added here. **Jump to section 2.4 if you do not wish to build custom metrics.**"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.3.1 Context Variable Count <a class=\"anchor\" id=\"context-variable-count\"></a>\nSome use cases require the use of context variables in order to track user inputs. For one customer, the assistant asks a series of questions in order to screen the patient. This section will identify based on context variables from within the `user_record` array. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Q1 = allLogsDF.groupby([\"user_record.calling_about_child\"])[\"conversation_id\"].nunique()\nQ1 = turn_dict_to_df(Q1, ['Yes/No', 'Count'])\nQ1['Question'] = 'Q1'\nQ1 = Q1[Q1['Yes/No'] != '']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Q2 = allLogsDF.groupby([\"user_record.covidExposure\"])[\"conversation_id\"].nunique()\nQ2 = turn_dict_to_df(Q2, ['Yes/No', 'Count'])\nQ2['Question'] = 'Q2'\nQ2 = Q2[Q2['Yes/No'] != '']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Q3 = allLogsDF.groupby([\"user_record.covidSymptoms\"])[\"conversation_id\"].nunique()\nQ3 = turn_dict_to_df(Q3, ['Yes/No', 'Count'])\nQ3['Question'] = 'Q3'\nQ3 = Q3[Q3['Yes/No'] != '']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "customVarDF = pd.concat([Q1,Q2,Q3]).reset_index(level=0,drop=True)\ncustomVarDF.to_csv(custName+'_ScreeningCount.csv',index=None)\nproject.save_data(file_name = custName + \"_ScreeningCount.csv\",data = customVarDF.to_csv(index=False),overwrite=True) # This saves in COS. Comment out if running locally\ncustomVarDF"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.3.2 Response Mentions <a class=\"anchor\" id=\"response-mentions\"></a>\nA specific customer wanted to identify all mentions of `311` in the responses to users. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "helpDF = allLogsDF[(allLogsDF['output.text'].str.contains('311')) | (allLogsDF['output.text'].str.contains('3-1-1'))] \nprint('Total 3-1-1 response mentions:', len(helpDF))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "newDF = pd.DataFrame(calculate_weekly_conversations(helpDF, week_offset))\nnewDF"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# ax = sns.barplot(x=\"week\", y=\"messages\", data=newDF,orient='v', palette=\"Blues_d\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2.4 Export to CSV <a class=\"anchor\" id=\"export-to-csv\"></a>\nSave important metrics and data from Pandas dataframes to CSV for use in Cognos Analytics dashboards and for deeper data exploration. The three CSV files will be saved to your Assets folder in your Watson Studio project. The files can be used to build visualizations in Cognos Dashboard.\n### 2.4.1 Save all logs to CSV"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# allLogsDF.to_csv(custName+'_logs.csv',index=False) # This saves if running notebook locally. Comment out for Studio. \nprint('Saving metrics to {}'.format(custName+ \"_logs.csv\"))\nproject.save_data(file_name = custName + \"_logs.csv\",data = allLogsDF.to_csv(index=False),overwrite=True) # This saves in COS. Comment out if running locally"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.4.2 Save KPIs to CSV"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "metricsDF = pd.DataFrame(metrics_dict)\n# metricsDF.to_csv(custName + \"_KeyMetrics.csv\",index=False) # This saves if running notebook locally. Comment out for Studio. \nproject.save_data(file_name = custName + \"_KeyMetrics.csv\",data = metricsDF.to_csv(index=False),overwrite=True); # This saves in COS. Comment out if running locally\nprint('Saving key metrics to {}'.format(custName+ \"_KeyMetrics.csv\"))\nmetricsDF"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.4.3 Save uncovered messages to CSV\nImprove Coverage by analyzing these uncovered messages. This might require adding training data to Intents or customizing STT models."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('\\nSaved', len(uncoveredDF), 'messages to:', custName + \"_uncovered_msgs.csv\")\n\nproject.save_data(file_name = custName + \"_uncovered_msgs.csv\",data = uncoveredDF.to_csv(index=False),overwrite=True); # This saves in COS. Comment out if running locally"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 3.0 Collecting data for blind testing or new ground truth <a class=\"anchor\" id=\"blind-testing\"></a>\nThis section is **optional** for those wishing to perform blind testing on user data. Whether we want to assess the performance of our classifier via a blind test or gather new ground truth training data we need a quick way to extract what our users are saying to open-ended questions.  There are multiple ways to extract these utterances depending on the type of assistant.\n\nRegardless of method the general recipe is:\n\n1. Extract user utterances and intents assigned by Watson Assistant\n2. Use SMEs to provide the actual intent of each utterance\n3. Assess test performance and update training (ie, via [Dialog Skill Analysis notebook](https://medium.com/ibm-watson/announcing-dialog-skill-analysis-for-watson-assistant-83cdfb968178))\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 3.1 Gathering initial user responses via hardcoded dialog turn number\nFor a single-skill assistant we can use the `dialog_turn_counter` field to extract utterances on a given turn.  This field uses a 1-based index, ie the first turn is index=1. (Python generally assumes a 0-based index).\n\nIf the user speaks first, search on USER_FIRST_TURN_COUNTER=1.  If the assistant speaks first, use USER_FIRST_TURN_COUNTER=2\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "USER_FIRST_TURN_COUNTER=2\nuserFirstTurnView = filteredLogsDF[filteredLogsDF['dialog_turn_counter']==USER_FIRST_TURN_COUNTER]\nuserFirstTurnDF = userFirstTurnView[[\"input.text\",\"intent\",\"intent_confidence\"]]\n\nuserFirstTurnDF.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 3.2 Write out the user utterances to a file\nDataframes are easily exported to a comma-separated file which is easily imported into Excel and other tools.\nFor a blind test you need at the user utterance and the predicted intent.\nWhen you have SMEs review the intents you should mindfully select one of these two options:\n\n1. Include the predicted intent and let the SME make corrections.  This is the fastest approach but may bias the SMEs towards what was already predicted.\n2. Remove the predicted intent.  This is more time-consuming for SMEs but generates unbiased labels.\n\nThis file-writing code can be used with any of the \"gather response patterns\" in this notebook."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Uncomment ONE of the patterns\n# Pattern 1: Write out all utterances and predictions\nuserFirstTurnDF.to_csv(custName+\"_utterances.csv\",index=False,header=[\"Utterance\",\"Predicted Intent\", \"Prediction Confidence\"])\n\n#Pattern 2: Write only the user utterance\n# userFirstTurnDF = userFirstTurnView[[\"input.text\"]]\n# userFirstTurnDF.to_csv(\"utterances2.csv\",index=False,header=[\"Utterance\"])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### End of Notebook v1.3 (last modified on 5-22-20)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}